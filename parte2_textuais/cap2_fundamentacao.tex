\chapter{Revisão Bibliográfica} \label{cap2}
\section{Fundamentação Teórica}
\subsection{Redes Neurais}
Redes neurais são modelos computacionais inspirados no sistema nervoso humano. Suas estruturas são subdivididas em camadas e unidades de processamento. As camadas representam a ordem nas quais os neurônios processam as informações. Os neurônios são as unidades de processamento, onde similarmente ao sistema nervoso, recebem um estimulo, processam e transmitem o estimulo aos demais neurônios da rede neural. A estrutura de um neurônio pode ser vista na figura a seguir:
\begin{figure}[H]
	\centering
    \label{fig1}
    \vspace{3ex}%
	\includegraphics[scale=0.7]{pasta1_figuras/neuronio_artificial.jpg}
    \caption{Neurônio Artificial}
\end{figure}

Como nos neurônios presentes no sistema nervoso, o neurônio artificial possui um meio de recepção dos estímulos vindos do meio externo, que são denominadas as entradas. Os pesos são atribuídos a cada entrada e estes podem sofrer alteração durante o processo de treinamento. O somador obtém o resultado da soma das multiplicações das entradas pelos pesos e transmite o potencial de ativação à função de ativação. A função de ativação aplicará a saída do somador em alguma função especifica obtendo assim, a saída da rede neural.

As topologias e arquiteturas de uma rede neural são definidas sob algumas especificações. Tais são elas: direção de fluxo de dados, tipo de aprendizado, algoritmo de aprendizado e a realimentação, disposição espacial dos neurônios.

Arquiteturas \textit{feedfoward} processam os dados em direção a saída, ou seja, a partir da camada de entrada o processamento dos dados ocorrerá de camada em camada, passando por todas as camadas escondidas até chegar na camada de saída. Um exemplo genérico de uma arquitetura \textit{feedfoward} pode ser visto na figura a seguir:
\begin{figure}[H]
	\centering
    \label{fig2}
    \vspace{3ex}%
	\includegraphics[scale=0.4]{pasta1_figuras/rna-Feedfoward.png}
    \caption{Rede neural totalmente conectada}
\end{figure}

Em algumas arquiteturas é possível encontrar também interconexões das camadas no sentido da camada de saída em direção a camada de entrada. Tal arquitetura é denominada recorrente. Um exemplo dessa topologia pode ser observada na figura 2.3.
\begin{figure}[H]
	\centering
    \label{fig3}
    \vspace{3ex}%
	\includegraphics[scale=0.35]{pasta1_figuras/redes-recorrentes.png}
    \caption{Redes recorrentes}
\end{figure}

Um dos conceitos fundamentais no projeto de redes neurais artificiais é o treinamento. O treinamento possui a função de ajustar os pesos da rede fazendo com que a mesma seja capaz de generalizar o aprendizado. Existem dois tipos de treinamento: Supervisionado e não supervisionado. O treinamento supervisionado é feito com o auxílio de um professor, ou seja, para um determinado conjunto de entradas existe uma saída conhecida e desejada. O aprendizado no treinamento não supervisionado será feito sem "professor" reconhecendo padrões, relações e regularidades sem conhecer as saídas.

Dentre os diversos algoritmos, destaca-se o \textit{backpropagation} pela sua capacidade de resolver problemas não-linearmente separáveis. Este algoritmo só é aplicável em arquiteturas multicamadas e o seu processo de ajustes de pesos se baseia na retro propagação do erro. A perceptron multicamada é uma das arquiteturas que utiliza deste algoritmo de treino para generalizar suas soluções não-linearmente separáveis. Um exemplo de PMC pode ser visto a seguir:
\begin{figure}[H]
	\centering
    \label{fig4}
    \vspace{3ex}%
	\includegraphics[scale=0.4,angle=-90]{pasta1_figuras/pmc.pdf}
    \caption{Perceptron multi camada}
\end{figure}

\textit{Overfitting} e \textit{underfitting} são classificações sobre a capacidade de generalização da rede. O overfitting ocorre quando a rede recebe treinamento demasiado das amostras do dataset, e no contrário, quando o treinamento é insuficiente ocorre o \textit{underfitting} da capacidade de generalização. Para validar se uma rede neural já atende as especificações ótimas de generalização, ou seja, o ponto ótimo entre o overfitting e o \textit{underfitting}. Alguns métodos de validação e testes já são utilizados no processo de treinamento de uma rede neural. Um muito conhecido é o método da validação cruzada, onde o dataset é dividido em 3 subconjuntos de amostras: Treino, validação e teste. O subconjunto do treino será o conjunto que treinará os pesos dos neurônios. Sob as amostras de validação serão calculados o erro até que se alcance a condição de parada. E por fim, o subconjunto de teste será usado para estipular os parametros da capacidade de generalização da rede. Na validação cruzada os subconjuntos de treino serão divididos em k partes iguais, onde cada k parte será o conjunto de validação durante uma certa quantidade de épocas de treino.
\subsection{Verificação}
Verificação é um método utilizado para verificar a corretude de uma certa propriedade sob o funcionamento de um sistema. Tal técnica visa a validação e a confiabilidade de uma propriedade específica. Verificação formal se divide em dois tipos de abordagens: a verificação dedutiva e a verificação de modelos. No caso da primeira abordagem, a verificação permite a prova de propriedades temporais em sistemas com estados infinitos. Já na segunda abordagem, a verificação de modelos, do inglês \textit{Model Checking}, trata do problema de testar de forma automática se um modelo de um determinado sistema atende a uma respectiva especificação, sendo que, por exemplo, tais especificações podem estar relacionadas com as propriedades de segurança e/ou de vivacidade do sistema em questão. Para solucionar este problema de forma algorítmica, é representado matematicamente o sistema e suas especificações utilizando métodos formais, como por exemplo, Lógica Proposicional e Lógica Temporal Linear, de tal forma que se possa verificar se uma dada fórmula é satisfeita dada uma determinada estrutura \cite{jhala2009}.

A expressão "verificação de modelos"  se refere a um algoritmo que explora o espaço de estados de um sistema a fim de verificar propriedades. Este também verifica se as transições dos estados respeitam as restrições impostas pelo sistema \cite{clarke2001}.  Tal algoritmo realiza uma verificação exaustiva no espaço de estados de maneira automática em busca de uma violação de restrição.


Um dos principais problemas enfrentados pelas técnicas de verificação de modelos até hoje é a explosão de estados. Tal problema ocorre quando os estados da estrutura obtida a partir do sistema em questão crescem exponencialmente \cite{clarke2001}. Embora, muitos ganhos já foram obtidos em relação a eficiência dos verificadores, a explosão de estados ainda é um problema crítico para as ferramentas hoje existentes.


Ferramentas de software que executam a técnica de verificação automática são chamadas de verificadores. Esses se baseiam nas teorias da verificação de modelos, que possuem o objetivo de verificar de maneira rápida e eficiente propriedades de um código. Com o crescimento da verificação formal em sistemas de software , muitas ferramentas foram desenvolvidas para verificar propriedades não usuais para diversos frameworks presente no mercado. A verificação de corrida de dados em GPUs é um exemplo que algumas ferramentas já verificam. Algumas destas são: ESBMC-GPU \cite{monteiro2018}, Gklee \cite{gklee}, GPUVerify \cite{gpuverify}, etc. 


O desenvolvimento desse projeto gira em torno do verificador ESBMC-GPU \cite{monteiro2018}, um verificador que é capaz de verificar as propriedades: estouro aritméticos de vetores, ponteiros nulos, corrida de dados, divisão por zero e assertivas definidas pelo usuário. Este verificador utiliza das técnicas da verificação de modelos e possui algumas características particulares.  


O ESBMC aplica técnicas de BMC (\textit{Bounded Model Checking}) baseado em SMT (\textit{Satisfiability Modulo Theories}) para verificar programas C/C++, e da linguagem CUDA, usada para programação de GPU. A técnica BMC possui a ideia básica de checar a negação de uma propriedade até uma determinada profundidade. Dado um sistema de transição de estados M, uma propriedade $\phi$, e um limite k, BMC desdobra o sistema k vezes e o traduz para uma condição de verificação (\textit{verification condition}, VC) $\Psi$, tal que $\Psi$ é satisfatível, se e somente se, $\phi$ possuir um contraexemplo de profundidade k ou menor \cite{cordeiro2012}.


SMT resolve as fórmulas de satisfatibilidade de primeira ordem usando a combinação de diferentes teorias e assim generaliza a satisfatibilidade proposicional por suportar funções não interpretadas, aritmética linear e não linear, vetores de bit, tuplas, arrays, e outras teorias de primeira ordem.


O ESBMC-GPU tem como base um algoritmo de exploração preguiçosa, que no lugar de verificar de uma única vez todas as possíveis intercalações de um programa, verifica de forma incremental uma intercalação por vez \cite{cordeiro2011}. O algoritmo percorre, em profundidade, a árvore de alcançabilidade de estados (\textit{Reachability Tree}, RT). Ao chegar em um nó folha, o algoritmo passa para o solucionador uma fórmula SMT que representa uma intercalação específica do programa CUDA. Caso esta fórmula seja satisfatível, uma violação da propriedade no programa CUDA foi encontrada e, assim, um contraexemplo é fornecido. Caso contrário, é realizado um \textit{backtrack} na RT e uma nova intercalação é produzida e verificada pelo solucionador SMT. O algoritmo termina quando ou uma violação é encontrada pelo ESBMC ou todas as intercalações foram verificadas com sucesso.


Além do algoritmo de exploração preguiçosa o ESBMC-GPU ainda utiliza da técnica MPOR (\textit{Monotonic Parcial Order Reduction}). Tal técnica é utilizada para reduzir as intercalações redundantes \cite{kahlon2009}. O algoritmo classifica as transições dentro de um programa multitarefa que são independentes ou dependentes de transições em outras threads, objetivando determinar se pares de intercalações sempre computam o mesmo estado, descartando os estados da RT que são duplicados \cite{morse2015}.


\subsection{CUDA}

CUDA é uma plataforma de computação paralela de propósito geral que representa um modelo de programação desenvolvido pela empresa NVIDIA para executar em GPUs fabricadas pela mesma. É uma linguagem desenvolvida para ter uma rápida curva de aprendizado, cujo o ambiente pode ser facilmente utilizado por programadores das linguagens C/C++ e/ou Fortran [NVIDIA 2015].

No modelo de programação de CUDA, o conceito de kernel é usado para uma função que executa n cópias paralelamente na GPU, onde n é o produto do número de blocos e threads. Um kernel é definido por um especificador \textunderscore\textunderscore global\textunderscore\textunderscore  e sua chamada no programa é feita pela notação kernel\textless\textless\textless B,T\textgreater\textgreater\textgreater, onde B é o número de blocos e T é o número de threads. Cada kernel é referenciado na GPU como thread e cada thread recebe um identificador único (ID) formado pelo número da thread e o número do bloco. O ID da thread é usado para indexar as suas tarefas (i.e., posições de memória e cooperação). As threads são organizadas em blocos.


Dentro de um bloco, a hierarquia de threads é definida pela variável chamada threadIdx. Esta variável é um vetor de três componentes permitindo usar índices uni-, bi- e tridimensionais. Por exemplo, para obter o ID de uma thread nestas configurações para um bloco bidimensional de tamanho (Dx,Dy), o ID da thread de índice (x,y) e obtido por (x+yDx), e para um bloco tridimensional de tamanho (Dx,Dy,Dz), a ID de uma thread de índice (x, y, z) é definido por (x + yDx + zDxDy) [NVIDIA 2015].


Os blocos também podem ser definidos em três dimensões, onde cada dimensão pode ser acessada pela variável blockIdx. Esta variável também é formada por três componentes permitindo usar blocos uni-, bi- e tridimensionais. O número máximo de threads por bloco depende da geração da placa variando de 1024 a 2048 [NVIDIA 2015]. Os blocos possuem a característica de serem executados em qualquer ordem, podendo ser alocados a qualquer processador. Com isso, um kernel pode ser executado por mútiplos blocos de forma igual, e o número total de threads é o número de blocos vezes o número de threads por bloco.


Um conceito utilizado na programação de CUDA, é fazer referência a GPU como device e a unidade de processamento central (CPU) como host.     device é um especificador para funções que executam e são chamadas somente pela GPU, e host para funções que executam e são chamadas somente pela CPU. O fluxo comum da alocação de dados para o device é feito no host usando as funções cudaMalloc, cudaFree e cudaMemcpy. Estas são funções essenciais para um programa CUDA, pois os dados são transferidos do host para o device e vice-versa. A função cudaMalloc aloca uma quantidade de memória no device, a qual é liberada após sua utilização pela função cudaFree. A função cudaMemcpy é usada para copiar dados inicializados no host para o device. Suas interfaces são baseadas nas funções malloc, free e memcpy da linguagem C.

Devido a eficiência do paralelismo das aplicações desenvolvidas em CUDA e em outras plataformas que operam nas GPUs de forma genérica, muitos ganhos foram obtidos em paralelizar operações. Um exemplo pode ser visto no comparativo de multiplicação de matrizes esparsas entre GPUs e CPUs em \cite{liang2017}.

APIs voltadas apenas para cálculo de matrizes e primitivas de ANNs surgiram nos últimos anos. CUblas e CUdnn são exemplo dessas APIs e foram desenvolvidas em CUDA pela empresa NVIDIA. Tais APIs possuem funções que executam diversas operações de forma paralela nas threads dos dispositivos \textit{many-cores}.

As ANNs são ,na maioria das vezes, sistemas que podem ser modelados por matrizes, e suas operações são baseadas majoritariamente em produtos e somas. Além dessas operações básicas, as ANNs também possuem funções de ativações especificas, podendo algumas até possuir camadas de convolução e \textit{pooling} que são muito utilizadas em reconhecimento de imagens \cite{Kim2017}. CUDNN e CUBLAS, trazem justamente esse \textit{gap}, onde os produtos e somas das matrizes, as primitivas funções das ANNs e operações de convolução e \textit{pooling} são executadas utilizando do paralelismo das GPUs \cite{wang2015}. 

\section{Trabalhos Relacionados}
% Fim Capítulo

Por ser um tema relativamente atual, a verificação de ANN já é uma área de pesquisa muito visada. As técnicas utilizadas neste projeto se baseiam nos seguintes trabalhos relacionados:

Em \cite{reluplex}, é proposto um verificador de ANNs voltadas para a função de ativação Relu. Este utiliza do método simplex \cite{Bartels1971} para poluir as amostras a serem verificadas. As contribuições são: (i) Reluplex, um SMT solver para a teoria da linear real arithmetic com ReLU constraints. (ii) Mostrar como DNNs e as propriedades de interesse podem ser codificadas como entradas para o Reluplex. (iii) discutir vários detalhes de implementações que são cruciais para performance e escalabilidade, como a aritmetica de ponto flutuante, limites de derivação para as variáveis ReLU e análise de conflitos. (iv) conduzir uma completa avaliação na implementação do protótipo ACAS XU system, demonstrando a habilidade escalável do Reluplex em DNNs que são maiores em ordem de magnitude que as outras que podem ser analizadas usando técnicas existentes.


 Em \cite{marta2016} é proposto um \textit{framework} de verificação para \textit{feed-forward multi-layer neural networks} baseadas em SMT. Este foca na segunraça das decisões nos reconhecimentos de imagens com respeito a manipulação de imagens, como por exemplo: arranhões, mudanças no ângulo da câmera e condições de luminosidade que resultariam no mesmo resultado classificado por um humano. A técnica utilizada se baseia numa busca exaustiva de uma região empregando discretização e propagando a analise camada por camada. O método lida diretamente com o código da ANN e pode garantir que os exemplos adversos, se existem, são encontrados pela dada região. As técnicas foram implementadas utilizando o SMT solver Z3\cite{z3}.
 
 Em \cite{kroening2018} é proposto uma metodologia de como testar a segurança de ANNs em domínios críticos. A metodologia se baseia no tradicional MC/DC \textit{coverage criterion} \cite{chang2007}. Os critérios de avaliação são incomparáveis e interdependentes. É proposto um algoritmo para geração de casos de teste baseado em LP (\textit{linear programming}, onde um novo caso de teste é obtido a partir de perturbações inseridas em outros casos de teste. Os métodos visam 4 objetivos: (1) busca de bugs; (2) métrica de segurança para DNNs; (3) eficiência do teste; (4) analise das estruturas internas de DNNs.
 
 
 
 
 
 
 
 
 
 
 
 